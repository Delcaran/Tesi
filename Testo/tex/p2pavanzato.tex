\chapter{Un'analisi più approfondita delle reti P2P}\label{unanalisi-piuxf9-approfondita-delle-reti-p2p}

%NOTA BENE: TUTTA STA ROBA NON SERVE PER BITCOIN. SI TRATTA DI UN APPROFONDIMENTO GENERICO PER RETI DI FILE SHARING IN CUI RISULTA FONDAMENTALE INDIVIDUARE CON PRECISIONE UN SINGOLO NODO O UN SINGOLO FILE. TUTTO QUESTO IN BITCOIN NON ESISTE.

Riprendiamo ora in modo più rigoroso i concetti generali espressi in precedenza. Chiamiamo il tipo di rete in analisi \emph{P2P overlay} e la definiamo come un grafo virtuale che connette i peer e che viene utilizzato per la ricerca di risorse, lo storage di file e gli algoritmi di gestione. È bene notare che la P2P overlay si trova a livello di applicazione, mentre le comunicazioni tra i peer sono punto-a-punto una volta che la connessione è stata stabilita.

Una P2P overlay può essere \emph{strutturata} o \emph{destrutturata}, a seconda della tipologia di connessione del grafo che la rappresenta. Nel caso strutturato è facile definire algoritmi precisi per la gestione delle risorse condivisi, mentre in grafi destrutturati l'approccio è più ``alla buona'' e richiede spesso l'utilizzo di tecniche di flooding o di \emph{random walk} come nel casodi Gnutella.

\section{Indicizzazione dei dati e overlays}\label{indicizzazione-dei-dati-e-overlays}

Qualsiasi sia la sua struttura, ammesso che ne abbia una, una rete P2P sfrutta una qualche forma di indice per localizzare i dati al suo interno. Possiamo distinguere tre metodologie diverse di indicizzazione:

Indice centralizzato: Vengono utilizzati alcuni server centrali che mantengono la posizione dei vari dati sui vari nodi. Questo è il metodo utilizzato nelle ricerche DNS e nelle prime reti P2P come Naptser.

Indice distribuito: L'indice generale è distribuito tra tutti i peer. Per accedere agli indici nella overlay viene utilizzata una struttura. Creare un indice distribuito efficente è una sfida molto complessa, e tra tutte le soluzioni proposte negli anni quella \emph{tabella hash distribuita} (\emph{DHT}) è tra le più efficaci. Esistono infatti molte varianti diverse dello schema DHT, ognuna con i propri algoritmi, vantaggi e debolezze, ma lo schema tipico prevede l'utilizzo di uno spazio delle chiavi piatto che mappa i nodi della rete con i dati in essi contenuti.
%TODO: immagine della mappa in prof 680
Nello specifico, l'indirizzo di un nodo viene mappato ad un identificatore nello spazio delle chiavi tramite una apposita funzione di hash. Allo stesso modo, ogni dato del nodo viene mappato nello stesso spazio delle chiavi tramite hash.

Indice locale: Ogni peer mantiene un indice dei propri dati locali e di quei dati remoti per cui deve effettuare una ricerca. È una forma di indicizzazione spesso utilizzata in reti non strutturate in cui è necessaria una query flood, come ad esempio Gnutella.

Esiste un altro criterio per classificare un meccanismo di indicizzazione, basato sulla semantica. Un \emph{indice semantico} è utilizzabile anche da un essere umano e può essere il nome di un file, una parola-chiave, una chiave in un database. Si parla di \emph{indice libero da semantica} quando non è leggibile da un essere umano, e spesso corrisponde ad un indice basato su funzioni matematiche come quella di hash, ad esempio lo schema DHT sopra descritto. Il vantaggio del primo rispetto al secondo sta nella possibilità di effettuare ricerche tramite parole chiavi, ricerche per range e anche ricerche basate su risultati approssimativi \footnote{ad esempio ricercare tutte le stringhe che   iniziano, finiscono o contengono una sottostringa o una espressione   regolare.}, tutte cose non supportate in un indice senza semantica.

\subsection{Indici distribuiti}\label{indici-distribuiti-todo-probabilmente-posso-eliminare}
%TODO: probabilmente posso eliminare questa sezione

In una overlay strutturata, la rete P2P ha una topologia ben definita e i dati sono localizzati secondo un criterio deterministico dipendente da algoritmi precisi. L'obiettivo di questa precisa struttura è fornire una ricerca molto rapida e deterministica per le query, pertanto tali sistemi vengono definiti \emph{sistemi di lookup} e tipicamente sfruttano tabelle di hash per localizzare i dati. Oltre allo svantaggio sopra indicato dell'impossibilità di effetture query approssimative, il calcolo dell'hash per ogni risorsa condivisa dai peer genera un certo overhead che potrebbe essere particolarmente gravoso in fase di churm.

D'altro canto, in una overlay non strutturata, dato che non esiste un metodo per stabilire la posizione di un file o di un nodo all'interno della rete, viene usato un \emph{indice locale} per ogni peer. Pur facilitando il churm, una query eseguita in questa rete può generare un grande numero di messaggi e un grande ritardo per la risposta. Tale svantaggio viene però bilanciato dalla possibilità di effettuare query approssimative. Nonostante l'assenza di un struttra definita, emergono alcune topologie, a seconda della funzione statistica che lega i nodi:

\textbf{Power law random graph} (PLRG): Questa topologia viene rappresentata da un grafo casuale in cui ogni nodo ha un certo numero di vicini (\emph{grado}) e si relaziona con gli altri nodi in base alla
\emph{Legge della Potenza} \footnote{Si tratta di una relazione   funzionale tra due quantità in cui una quantità varia in base ad una   potenza dell'altra.}. Se ordiniamo i nodi in base al grado, allora l'$i$-esimo nodo avrà $c/i^\alpha$ vicini con $c$ costante.

\textbf{Normal random graph}: In questo nodo la distribuzione dei nodi risponde alla distribuzione normale, per cui il grado di ogni peer risulta essere tipicamente uniforme.

\section{Overlay non strutturati}\label{overlay-non-strutturati}

Essendo privi di algoritmi per il posizionamento di dati e nodi, una ricerca eseguita in queste reti presenta alcune sfide che vale la pena trattare.

\subsection{Proprietà}\label{proprietuxe0}

Come accennato, lo svantaggio principale nelle overlay non strutturate sta nella ricerca: essa può richiedere lungo tempo e può risultare infruttuosa anche nel caso in cui la risorsa cercata esista e sia disponibile. Esistono però alcuni vantaggi:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Supporto le query complesse basate su range, attributi e valori   approssimati.
\item
  Un churm elevato non rappresenta un problema, la connessione e la   disconnessione di molti nodi risulta sempre rapida e non influisce   sulle performance.
\end{itemize}

Tali vantaggi sono validi nella maggior parte delle implementazioni di una overlay non strutturata, come ad esempio in Gnutella, ma se vengono soddisfatte alcune condizioni sono valide anche le seguenti proprietà: 
\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Se esiste un certo grado di replicazione dei dati, le ricerche   risultano efficienti
\item
  L'utenza tipa è soddisfatta con ricerche di tipo best-effort.
\item
  Se la rete non è troppo vasta, non ci sono problemi di scalabilità   durante la ricerca.
\end{itemize}

\subsection{Ricercare in reti non strtturate}\label{ricercare-in-reti-non-strtturate}

Prendiamo il caso della rete Gnutella come esempio generico e analizziamo nel dettaglio le metodologie di ricerca.

Consideriamo un sistema con $n$ nodi e $m$ oggetti. Definiamo $q_i$ come la popolarità dell'oggetto $i$, ovvero la frazione di query rispetto al totale che richiedono l'oggetto $i$. La popolarità può essere equivalente per tutti gli oggetti oppure seguire la topologia PLRG precedentemente nominata. In quest'ultimo caso nell'analisi utilizzeremo la variante della distribuzione enunciata da Zipf, particolarmente indicata per descrivere la frequenza di un'occorrenza in un insieme di occorrenze. 
%TODO fonte per Zipf
Con queste considerazioni abbiamo:

\[ \sum^m_{i=1} q_i = 1 \]

dove

\[ \begin{array}{ll} 
    q_i = \frac{1}{m} & \textrm{con distribuzione uniforme} \\
    q_i \propto i^{-\alpha} & \textrm{con distribuzione di Zipf}
    \end{array}
\]

Stabiliamo poi che $r_i$ sia il numero delle copie esistenti dell'oggetto $i$, e $p_i$ sia la frazione di tutti gli oggetti che sono una copia di $i$. Esistono tre tipologie di distribuzione che possono descrivere la replicazione: uniforme, proporzionale e quadratica. Per cui:

\[ \sum^m_{i=1} r_i = R \] \[ p_i = \frac{r_i}{R} \]

con

\[ \begin{array}{ll} 
    r_i = \frac{R}{m} & \textrm{con distribuzione uniforme} \\
    r_i \propto q & \textrm{con distribuzione proporzionale} \\
    r_i \propto \sqrt{q_i} & \textrm{con distribuzione quadratica}
    \end{array}
\]

Con una replicazione uniforme, tutti gli oggetti hanno lo stesso numero di copie e dunque le performance per tutte le ricerche sono identiche. Con una popolarità uniforme, gli schemi di replicazione proporzionale e quadratica si riducono allo schema di replicazione uniforme.

Per misurare le perfomance vengono impiegate varie metriche, tra le più popolari ci sono:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  La probabilità di query-hit.
\item
  Ritardo o numero di inoltri di query necessari per il query-hit.
\item
  Numero di messaggi processati da ogni nodo coinvolto nella ricerca.
\item
  Copertura dei nodi, ovvero il numero di nodi distinti visitati.
\item
  \emph{duplicazione dei messaggi}, calcolabile come   $\frac{(\textrm{#messaggi} - \textr{#nodi_visitati})}{\textrm{#messaggi}}$.
\item
  massimo numero di messaggi in un nodo.
\item
  \emph{recall}, definitio come il numero di oggetti trovati che   soddisfano i criteri ricercati (questa metrica è rese possibile dalle   query complesse permesse in una overlay non strutturata).
\item
  \emph{efficienza dei messaggi}, ovvero i recall ottenuti per ogni   messaggio.
\end{itemize}

Queste metriche potrebbero essere influenzate nel caso in cui le ricerche non siano indipendenti l'una dall'altra. Nelle ricerche definite \emph{guidate} infatti, un nodo mantiene alcune informazioni ottenute dalle ricerche precedenti, in modo da ottimizzare i risultati delle ricerche successive. Dato che esistono numerosi metodi per raccogliere e utilizzare i dati di una ricerca, in questa trattazione si discuteranno solo ricerche non guidate. \textbackslash{}\textbackslash{} Abbiamo visto nel capitolo precedente il metodo di ricerca detto \emph{flooding}, ne abbiamo visto le problematiche e analizzato la soluzione del Time-To-Live dei pacchetti di ricerca con i suoi vantaggi e le sue criticità. Il TTL rappresenta una sorta di miglioramento rispetto alla prima soluzione proposta per il flooding, il \emph{checking}. In questo metodo ogni nodo contatta il nodo di origine della query per vedere se inoltrare o meno la query. La soluzione viene considerata non pratica a causa dell'elevatissimo numero di messaggi scambiati e il carico eccessivo imposto sul nodo che effettua la query, che deve infatti gestire i messaggi di moltissimi nodi. Invece un raffinamento ulteriore del TTL consiste nell'implementazione di un \emph{anello di espansione}. Seconda questa strategia il nodo effettua un primo flooding con un piccolo TTL. In caso di insuccesso, la ricerca viene rifatta con un TTL maggiore e ripetuto all'occorrenza. Il successo di questa strategia è tanto maggiore quanto maggiore è il numero di repliche. In linea di massima, l'anello di espansione ha molto più successo rispetto al TTL qualsiasi strategia di replicazione si utilizzi e per qualsiasi tipo di popolarità, il tutto al prezzo di un leggero aumento del ritardo. Ciononostante, tutte queste strategia sono basate sul flooding e generano quindi messaggi duplicati. \textbackslash{}\textbackslash{} Un'alternativa al flooding utilizzabili in reti destrutturate è il \emph{random walk}. Come dice il nome, una query viene inoltrata in modo casuale ad un altro nodo quando viene ricevuta. Il random walk risolve il problema dei messaggi duplicati a scapito di un aumento della latenza di ricerca. Per risolvere anche questo problema si può aumentare il numero di nodi casuali a cui la query viene inoltrata ad un valore $k$, implementando il \emph{k random walk}. Per terminare la ricerca, la strategia più efficace consiste nell'unire il checking con il TTL: ogni \emph{walker}, alla scadenza del TTL, controlla con il nodo di origine della query se terminare la ricerca o meno. Il TTL viene utilizzato per evitare la creazione di cicli, e solitamente viene impostato ad un valore molto elevato.

Il random walk risulta più performante rispetto al flooding e offre anche molta più scalabilità.

%TODO strategie di replicazione??

\section{Chord Distributed Hash Table}\label{chord-distributed-hash-table}

Questo algoritmo per le DHT utilizza uno spazio delle chiavi piatto per associare le mappe tra i nodi e i dati condivisi. Sia l'indirizzo del nodo che i dati sono mappati ad un identificatore nello spazio delle chiavi tramite una funzione di hash. Sia il mapping delle chiavi che il mapping dei nodi dovrebbero assicurarsi che le chiavi siano uniformemente distribuiti tra tutti i nodi. Questo inoltre riduce la possibilità che i calcoli da effettuare durante il churm generino troppo overhead. Nello specifico, quando un nodo lascia o si unisce ad una rete con $n$ nodi, solamente $O(1/n)$ chiavi devono essere spostate in altri nodi. L'algoritmo Chord supporta una sola operazione, \emph{lookup(x)}, che mappa una data chiave $x$ ad un nodo della rete. Chord salva un dato nel nodo mappato dalla chiave di tale dato, il richiede due step:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Mappare il dato alla sua chiave nello spazio degli indirizzi comune.
\item
  Mappare la chiave al nodo utilizzando \emph{lookup}. La progettazione   di \emph{lookup} è la sfida di questo algoritmo.
\end{enumerate}

In questo algoritmo, l'indirizzo IP viene passato ad una funzione di hash che genera un identificatore di $m$ bit che identifica il nodo nello spazio comune delle chiavi. Anche i dati vengono passati ad una funzione di hash che genera sempre una chiave da $m$-bit. Il valore $m$ viene deciso a priori per evitare di generare collisioni con in fase di hashing. Chord utilizza un anello logico di dimensione $2^m$, per cui lo spazio delle chiavi è ordinato su tale anello logico con modulo $2^m$ \footnote{Nei successivi conti il modulo $2^m$ verrà sottinteso.}.

Una chiave $k$ viene assegnata al primo nodo tale che l'identificatore di tale nodo equivale o è successivo all'identificatore della chiave $k$ nello spazio degli identificatori, e tale nodo viene chiamato \emph{successore di k} e denotato come \emph{succ(k)}. Ad esempio, in un anello con $m=7$ abbiamo i nodi N5, N18, N23, N28, N63, N73, N99, N104, N115 e N119. Sei chiavi K8, K15, K28, K53, K87 e K121 vengono distribuite tra questi nodi come segue: \emph{succ}(8)=18, \emph{succ}(15)=18, \emph{succ}(28)=28, \emph{succ}(53)=63, \emph{succ}(87)=99, \emph{succ}(121)=5.

\subsection{Esempi di ricerca mediante chiavi}\label{esempi-di-ricerca-mediante-chiavi}

In un primo, semplice, algoritmo per il lookup, ogni nodo contiene solo un valore nella sua tabella di routing e memorizza unicamente il suo successore nell'anello dei nodi. Ogni query per la chiave $x$ viene inoltrata tra i nodi fin quando raggiunge un nodo il cui identificatore $y$ è maggiore della chiave $x$ modulo $2^m$. Il risultato torna al nodo di partenza seguendo il percorso inverso. Questo semplice algoritmo richiede $O(1)$ di spazio locale ma $O(n)$ salti tra gli $n$ nodi.

%TODO algoritmo 18.1 pag 690 (specificare notazione descritta in fondo a pag 689) 
%TODO grafico di ricerca 18.2 pag 689

Una versione più raffinata del precedente algoritmo richiede l'aumento dello spazio locale di archiviazione per le tabelle di routing a $O(n)$ ma permette di ridurre il numero dei salti tra i nodi a $O(\log n)$. Ogni nodo $i$ mantiene una tabella di rounting chiamata di indice (\emph{finger table}), con al massimo $O(\log n)$ valori distinti, costruita in modo tale che l'$x$-esimo valore (con $1 \leq x \leq m$) sia l'identificatore per il nodo \emph{succ}$(i + 2^{x-1})$ (più formalmente \emph{i.finger{[}$x${]} = succ}$(i + 2^{x-1})$). Tale nodo risulta essere il primo nodo la cui chiave è maggiore della chiave del nodo $i$ per un valore pari ad almeno $2^{x-1}\text{*mod*}2^m$.

A causa della sua struttura logaritmica, la finger table contiene più informazioni sui nodi successivi vicini rispetto ai nodi successivi lontani \footnote{qui ``successivi'', ``vicini'' e ``lontani'' fanno   riferimento all'anello che si viene a creare nella Chord overlay.}. Immaginiamo infatti di cercare la chiave $k$ partendo dal nodo $i$. Se $k$ si trova tra $i$ e il suo successore, allora vuol dire che $k$ si trova effettivamente nel successore. Altrimenti $k$ si trova oltre il successore, per cui $i$ deve scandire la sua finger table per identificare il nodo $j$ che precede immediatamente $k$. Dato che $j$ si trova più vicino a $k$ di $i$, esso conterrà molte più informazioni utili alla localizzazione di $k$.

%TODO gestione del churm in una Chord (pagg 691-695)
